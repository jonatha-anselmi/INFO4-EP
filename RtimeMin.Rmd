---
title: "Response time minimization in two parallel queues<br><small>Évaluation de Performances 2024, TD #2, INFO4, Polytech Grenoble</small>"
author: "Jonatha Anselmi"
date: "2024-02-22"
output: html_document
---

## Response time minimization in two parallel queues

### Problem statement

We consider two heterogeneous G/G/1 queues in parallel.
Upon arrival, a job is routed to queue one resp. two with probability $p$ resp. $1-p$.
The goal is to find the probability $p^*$ that minimizes the mean waiting time.

Unfortunately, no exact formula is available for the mean waiting time of the G/G/1 queue in general.
Given this difficulty, we can approach this problem either by simulation or by approximations.
In the former case, we rely on Lindley's equation (no need to use [the general code written for the G/G/1 queue](https://rpubs.com/janselmi/GG1_scheduling_disciplines)) while in the latter, we assume that the arrival process is Poisson and  rely on the Pollaczek–Khinchine formula.
We will assess the accuracy of the approximation given by the Pollaczek–Khinchine formula with respect to the optimal probability computed via simulation.


### Assumptions

We assume that the service rate at queue $i$ is $\mu_i$ and that the arrival rate is $\lambda$.
We assume that the job sizes are independent and identically distributed. We let $S$ denote a random variable having the distribution of the job size.
For stability, we assume that $\lambda \mathbb{E}[S]<\mu_1+\mu_2$.

### Approximation via Pollaczek–Khinchine formula

Using the Pollaczek–Khinchine formula and the Poisson decomposition property, the mean waiting time of a random job, say $W=W(p)$, is given by
$$
W(p) 
= p W_1(p) + (1-p) W_2(p) 
= p \times \frac{\lambda p}{2} \frac{ \mathbb{E}[(S/\mu_1)^2]}{1-\lambda p/\mu_1} + (1-p) \times \frac{\lambda (1-p)}{2} \frac{\mathbb{E}[(S/\mu_2)^2]}{1-\lambda(1-p)/\mu_2}
$$
and we are interested in minimizing $W(p)$ over $p$. Note that $W(p)$ is strictly convex, so a unique minimizer exists (say $p^*$). Differentiating, we obtain
$\frac{{\rm d} W(p)}{{\rm d} p} =0$ if and only if
$$
\frac{{\rm d} }{{\rm d} p} \left(\frac{1}{\mu_1} \frac{p^2}{\mu_1-\lambda p}  +  \frac{1}{\mu_2} \frac{(1-p)^2}{\mu_2-\lambda(1-p)} \right) = 0
$$
i.e., if and only if
$$
\frac{1}{\mu_1} \frac{2p\mu_1 - \lambda p^2}{(\mu_1-\lambda p)^2} = \frac{1}{\mu_2} \frac{2(1-p) \mu_2 - \lambda (1-p)^2}{(\mu_2-\lambda(1-p))^2}.
$$
This quartic equation is not trivial to solve analytically, but we can always solve it numerically.


### Optimization via simulation

For all $n=1,2,\ldots,N$, let $W_{1,n}$ and $W_{2,n}$ denote the waiting times of the $n$-th job joining the system if it is sent to queue 1 and 2, respectively; we can assume $W_{1,n}=W_{2,n}=0$.
Using Lindley's equation, for $i=1,2$ we obtain
$$
W_{i,n+1} = 
$$
where $U_{n}=i$ if job $n$ was sent to $i$, $I_E$ is the indicator function of the event $E$, $A_n$ denotes the inter-arrival time between jobs $n$ and $n+1$, and $S_n$ is the job size of job $n$.
Now, we write a code that iterates over this equation and plots the average waiting time $\frac{1}{N}\sum_{n=1}^N W_n$ as a function of $p$.

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)

LB_random <- function(N,p,mu,InterArrival,JobSize) {      

  WaitingTime=rep(0,2);
  WaitingTimeCum=rep(0,2);
  
  for (n in 1:N) #for each job
  {
    # Dispatching decision of RANDOM
    ... 
    for (k in 1:2) #for each server
    {
      # Update the waiting time of server k (Lindley's recursion)
      ...
    }
    WaitingTimeCum[U] = WaitingTimeCum[U]+WaitingTime[U];
  }

 return(sum(WaitingTimeCum)/N);
}

################################################################################
N=1e5; # number of jobs to simulate
set.seed(17); # Set seed for reproducibility

mu = sample(x=1:3, 2, replace = TRUE); # service rates
mu = c(1,3);

# Job size Scenario 1
# xm=1; xM=1e3; beta=0.8;
# JobSize=sample(c(xm,xM),N,replace=T,prob=c(1-1/xM^beta,1/xM^beta)); # Job sizes
# ES=xm*(1-1/xM^beta) + xM^(1-beta); # Expected value of job sizes
# ES2=mean(JobSize*JobSize);

# Job size Scenario 2
JobSize=rexp(N,1); # Job sizes
ES=1;  # E[S]:   Expected value of job sizes
ES2=1; # E[S^2]: Second moment of job sizes

# For stability, we want lambda*p*ES<mu[1] AND lambda*(1-p)*ES<mu[2] 
# Therefore, p < mu[1]/(ES*lambda) AND p > 1-mu[2]/(lambda*ES)
p_min=max(0.98*(1-mu[2]/(lambda*ES)),0);
p_max=min(0.98*(mu[1]/(ES*lambda)),1);
step=(p_max-p_min)/10;
p_values=seq(p_min, p_max, step);
W_RANDOM=rep(NA,length(p_values));

rho=0.8; # network load to test: lambda*E[S]/(mu_1+mu_2)

lambda = rho*sum(mu)/ES; # arrival rate
InterArrival = rexp(n=N, rate = lambda);           # Inter-arrival times: Poisson
# InterArrival = runif(n=N, min = 0, max=2/lambda);    # Inter-arrival times: Uniform

cnt=1;
for (p in p_values) 
{
    W_RANDOM[cnt]=LB_random(N,p,mu,InterArrival,JobSize);
    cat(paste("Avg Waiting Time (p=", round(p,digits=3), ")=", round(W_RANDOM[cnt],digits=3),sep=""), "\n");
    cnt=cnt+1;
}


# function to optimize: W(p)
my_fun=function(p,lambda,mu,ES2) 0.5*ES2*((lambda*p^2)*( (1/mu[1])^2)/(1-lambda*p/mu[1]) + (lambda*(1-p)^2)*((1/mu[2])^2)/(1-lambda*(1-p)/mu[2]))
res<-optimize(my_fun,lower=p_min,upper=p_max,p,lambda,mu,ES2,maximum=FALSE)
W_approx=res$objective;
p_star_approx=res$minimum;
cat(paste("Optimal waiting time and probability given by the approximation: W*=", 
    round(W_approx,digits=3), " p*=",round(p_star_approx,digits=3), sep=""), "\n");


# plot the results
plot(p_values, W_RANDOM, xlim=c(p_min,p_max), ylim = c(0, 1.1*mean(W_RANDOM,na.rm = T)),
     col="blue", lty=1, ylab="",xlab="probability p", type = "b", pch = 19, main=paste("Average Waiting Time W(p)"));
abline(h = W_approx, col="red", ylab="W*");
abline(v = p_star_approx, col="red");
legend("topright",legend=c("Simulation","W_approx"), col=c("blue","red"), pch=c("o","*","+"),lty=c(1,2), ncol=1);

axis(side=1,at=p_star_approx,  labels="p*");
axis(side=2,at=W_approx,  labels="W*");
    
grid(nx = NULL, ny = NULL, lty = 2, col = "lightgray", lwd = 1)


```

The optimal average waiting times returned by the approximation and by the simulation may be close to each other. What matters most is that the *the optimal routing probabilities returned by the approximation and by the simulation are very close to each other*.
Therefore, the Poisson approximation seems to work well, in theory.

### Arrival times from a real HPC workload

Now, let's look at the quality of the Poisson approximation when the arrival times are taken from a real High Performance Computing (HPC) workload.
Real data traces are available from the [Parallel Workloads Archive](http://www.cs.huji.ac.il/labs/parallel/workload/logs.html).



<br><br>








