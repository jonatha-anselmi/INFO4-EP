---
title: "Basic Auto-scaling<br><small>Ã‰valuation de Performances 2024, TD #2, INFO4, Polytech Grenoble</small>"
author: "Jonatha Anselmi"
date: "2024-02-22"
output: html_document
---

### Auto-scaling

Auto-scaling is a powerful mechanism for the efficient management of serverless, edge and cloud computing systems, both from the perspective of user-perceived performance and overall power consumption. It allows the *net* service capacity to scale up or down in response to the current load and the latter distributes incoming jobs across the set of available servers. 

In auto-scaling systems, servers can be in three states: warm, cold and initializing. A server is said \emph{warm} if turned on, \emph{cold} if turned off and \emph{initializing} if making the transition from cold to warm.
An initializing server performs basic startup operations such as connecting to database, loading libraries, etc. This is the time to provision a new function instance. Only warm servers are allowed to receive jobs.
A server is also said \emph{idle-on} if warm but not processing any job, and \emph{busy} if warm and processing some job.
Typically, billing policies charge per number of warm and initializing servers used per time unit.

Our aim is to evaluate the performance of some basic auto-scaling models via simulation in R.


### M/M/K/K queueing model

A first basic model for autoscaling is given by a $M/M/K/K$ queue. Here, the interpretation is that $K$ represents the nominal capacity, i.e., the maximum number of servers that can be up and running. Then, if $n_t$ is the number of jobs in the system at time $t$, then $n_t$ also represents the number of busy servers. Therefore, $K-n_t$ may model the number of cold servers, provided that

  1. a server becomes cold immediately after processing a job (or equivalently, the expiration rate is very high so that it can be ignored).
  
  2. servers cannot enter the initialization phase (or equivalently, the initialization rate is very high so that it can be ignored).

The $M/M/K/K$ queue can be described by a continuous-time Markov chain with state space $S=\{0,1,\ldots,K\}$ and transition matrix $Q=(q_{i,j})$ where all the non-zero elements are $q_{i,i+1}=\lambda$ for all $i=0,\ldots,K-1$ and $q_{i,i-1}=i{\mu}$ for all $i=1,\ldots,K$.
Here, $\lambda$ is the arrival rate of jobs and $\mu$ is the service rate of each server.

Let us write a code to simulate the M/M/K/K queue.

```{r eval=TRUE, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)

simulate_MMKK <- function(lambda, mu, K){
  
  N=1e5; # number of events to simulate;

  p_reject=0; # blocking probability
  p_reject_transient=rep(N, 0); # transient blocking probability
  T=0; # simulation time
  
  # a state is the number of jobs (or warm servers) currently in the system
  state=0;  #initial state
  
  for (i in 1:N) {
  
    U=lambda+state*mu;
    time_in_state=rexp(1,U)
    T=T+time_in_state;
  
    if (state==K) {
      # For the moment, let us find the overall time spent in state K
      p_reject=p_reject+time_in_state;
    }
  
    p_reject_transient[i]=p_reject/T;
  
    if (runif(1)<lambda/U){
        # An arrival occurred
        if (state<K){
          # The incoming job has room so it is accepted
          state=state+1;
        }
    } else {
        # A departure occurred
        state=state-1;    
    }
  }
  
  # The blocking probability by simulation
  p_reject=p_reject/T;
  
  # The blocking probability by theory (The Erlang B formula)
  p_reject_theory=0; 
  normalizing_constant=0;
  for (i in 0:K){
    normalizing_constant = normalizing_constant + (lambda/mu)**i / factorial(i);
  }
  
  p_reject_theory = (lambda/mu)**K / factorial(K);
  p_reject_theory = p_reject_theory / normalizing_constant;
  
  
  # Print the reject probabilities (simulation and theory)
  events=1:N;
  plot(events, p_reject_transient, type = "l", lty = 1)
  abline(h = p_reject_theory, col="red")
  legend("bottomright", legend = c("Reject prob. by simulation", "Reject prob. by theory - Erlang B formula"), col=1:2, pch=1);
  
  print(paste("Reject probability: ",p_reject," (by simulation)"));
  print(paste("Reject probability: ",p_reject_theory," (by theory - Erlang B formula)"));
}
```


Let's simulate.

```{r eval=TRUE, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)

set.seed(13); # Set seed for reproducibility
K=10;         # number of servers
lambda=0.6*K; # arrival rate
mu=1;         # service rate

simulate_MMKK(lambda,mu,K);

```


### M/M/K/K queueing model + expiration rate

Let us now go further. Building on the M/M/K/K queue, we want to add the feature that when a server becomes idle-on, it goes cold by itself after a (non-negligible) scale down delay, or \emph{expiration time}, provided that during such time the server received no job. This scale-down rule is common in serverless computing platforms.

Our goal here is **to calculate (by simulation) the fraction of jobs that find no idle-on server when they arrive**. Let's refer to this probability as $p_{\rm wait}$.

Let us first model this setting. We define a continuous-time Markov chain with state space $S=\{(i,j)\in\mathbb{N}^2:i+j\le N\}$ where $i$ resp. $j$ represents the number of busy resp. idle-on servers. The transition rate matrix $Q=(q_{i,j})$ where, from a generic state $(i,j)$, the non-zero rates are
$$
\begin{cases}
q_{(i,j),(i+1,j-1)} = \lambda  & \mbox{if } i<K \mbox{ and } j>0\\
q_{(i,j),(i,j)} = \lambda  & \mbox{if } i<K \mbox{ and } j=0\\
q_{(i,j),(i-1,j+1)} = i\mu  & \\
q_{(i,j),(i,j-1)}   = j\gamma & \\
\end{cases}
$$
Here, $\lambda$ is the arrival rate of jobs, $\mu$ is the service rate of each server and $\gamma$ is the expiration rate of each server.
We are particularly interested in the how often the transition $(i,0) \to (i+1,0)$ occurs. In fact, this transition models a job that finds no idle-on server upon arrival, implying that a cold server immediately becomes warm (and busy).

Now, let us write a code that simulates this Markov chain.

```{r eval=TRUE, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)

simulate_MMKK_plus_expiration <- function(lambda, mu, gamma, K){
  
  N=1e5; # number of events to simulate;

  num_jobs=0;      # overall number of jobs that arrived
  num_jobs_wait=0; # overall number of jobs that found no idle-on server upon arrival
  
  p_wait_transient=rep(N, 0);
  T=0; # simulation time
  
  # a state is the pair (busy, idleon). 
  busy=0; idleon=K;  #initial state 
   
  for (i in 1:N) {
  
    U=lambda+busy*mu+idleon*gamma;
    time_in_state=rexp(1,U);
    T=T+time_in_state;

    rnd=runif(1)
    if (rnd<lambda/U){
      # An arrival occurred

      # update performance measures
      num_jobs=num_jobs+1;
      if (idleon==0){
        num_jobs_wait=num_jobs_wait+1;
      }
      
      if (busy<K) {
        busy=busy+1;
        if (idleon>0) {
          idleon=idleon-1;
        }
      }

    } else if (rnd<(lambda+busy*mu)/U) {
      # A departure occurred
      busy=busy-1;
      idleon=idleon+1;
    } else {
      # A server expiration occurred
      idleon=idleon-1;      
    }

    p_wait_transient[i]=num_jobs_wait/num_jobs;

  }
  
  p_wait=num_jobs_wait/num_jobs;

  # Print p_wait
  print(paste("p_wait = ",p_wait));
  events=1:N;
  plot(events, p_wait_transient, type = "l", lty = 1)
  legend("bottomright", legend = c("Transient behavior of p_wait"), col=1:1, pch=1);
}
```


Let's simulate.

```{r eval=TRUE, include=TRUE}
knitr::opts_chunk$set(echo = FALSE)

set.seed(10); # Set seed for reproducibility
K=10;         # number of servers
lambda=0.6*K; # arrival rate
mu=1;         # service rate
gamma=0.25;   # expiration rate

simulate_MMKK_plus_expiration(lambda,mu,gamma,K);

```

###  [HOMEWORK] M/M/K/K queueing model + expiration rate + initialization rate

The natural step forward is to develop a model and associated code that includes non-negligible initialization rates (say $\alpha$ is the rate at which a server goes from cold to warm). How does the state space and transition rate matrix change?

<br><br><br>
